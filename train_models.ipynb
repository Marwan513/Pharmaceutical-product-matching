{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries\n",
    "\n",
    "This cell imports various Python libraries needed for data processing, machine learning, and text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from time import time\n",
    "from rapidfuzz import process, fuzz\n",
    "from deep_translator import GoogleTranslator\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Preparing the Dataset\n",
    "\n",
    "This section loads The Excel file containing product matching data.  \n",
    "It reads two sheets:  \n",
    "1. **Master File** - Likely contains reference product names.  \n",
    "2. **Dataset** - Contains new product names that need to be matched.  \n",
    "Duplicates in the dataset are removed to ensure data consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Excel dataset\n",
    "file_path = \"Product Matching Dataset.xlsx\" # edit the path if you want to train on another data\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# Read both sheets\n",
    "master_file = pd.read_excel(xls, sheet_name=\"Master File\")\n",
    "dataset = pd.read_excel(xls, sheet_name=\"Dataset\")\n",
    "\n",
    "# Remove duplicate entries from the dataset\n",
    "dataset = dataset.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Missing Product Names\n",
    "\n",
    "This section extracts product names from both the dataset and master file  \n",
    "to identify missing product names that are present in the master file but not in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get missing product names\n",
    "existing_names = set(dataset[\"marketplace_product_name_ar\"].unique())\n",
    "all_names = set(master_file[\"product_name_ar\"].unique())\n",
    "missing_names = list(all_names - existing_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `augment_name(name)`\n",
    "\n",
    "This function generates **augmented variations** of a given product name  \n",
    "to simulate different possible representations of the same name.  \n",
    "It applies multiple random transformations such as:\n",
    "- **Shuffling words** within the name\n",
    "- **Removing digits** (e.g., `0`)\n",
    "- **Deleting random characters** from words\n",
    "- **Replacing random characters** with Arabic letters\n",
    "- **Appending random suffixes** (e.g., `\"جديد\"`, `\"سعر جديد\"`)\n",
    "\n",
    "This is useful for training models that need to handle variations in  \n",
    "product naming conventions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_name(name):\n",
    "    \"\"\"\n",
    "    Generates augmented variations of the input name by applying random transformations.\n",
    "    \n",
    "    Args:\n",
    "        name (str): The original product name.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of unique augmented product names.\n",
    "    \"\"\"\n",
    "    augmented_names = set() # Store unique augmented names\n",
    "\n",
    "    for _ in range(70): # Generate multiple variations\n",
    "        modified_name = name\n",
    "\n",
    "         # Randomly shuffle words in the name (50% probability)\n",
    "        if random.random() < 0.5:\n",
    "            words = modified_name.split()\n",
    "            if len(words) > 1:\n",
    "                random.shuffle(words)\n",
    "                modified_name = \" \".join(words)\n",
    "\n",
    "        # Randomly remove the digit '0' from the name (50% probability)\n",
    "        if random.random() < 0.5:\n",
    "            modified_name = re.sub(\"0\", \"\", modified_name, 1)\n",
    "\n",
    "        words = modified_name.split()\n",
    "\n",
    "        for i, word in enumerate(words):\n",
    "            # Randomly delete a character from words longer than 5 letters (50% probability)\n",
    "            if len(word) > 5 and random.random() < 0.5:\n",
    "                idx = random.randint(0, len(word) - 1)\n",
    "                words[i] = word[:idx] + word[idx+1:]\n",
    "\n",
    "            # Randomly replace a character with an Arabic letter (50% probability)\n",
    "            if len(word) > 5 and random.random() < 0.5:\n",
    "                idx = random.randint(0, len(word) - 1)\n",
    "                new_char = random.choice(\"ابتثجحخدذرزسشصضطظعغفقكلمنهوي\")\n",
    "                words[i] = word[:idx] + new_char + word[idx+1:]\n",
    "\n",
    "        modified_name = \" \".join(words)\n",
    "        \n",
    "        # Randomly append a suffix (50% probability)\n",
    "        if random.random() < 0.5:\n",
    "            suffix = random.choice([\"جديد\", \"سعر\", \"سعر جديد\", \"س ج\"])\n",
    "            modified_name = f\"{modified_name} {suffix}\".strip()\n",
    "            \n",
    "        # Add the modified name to the set (ensuring uniqueness)\n",
    "        augmented_names.add(modified_name)\n",
    "\n",
    "    return list(augmented_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmenting Missing Product Names and Expanding the Dataset\n",
    "\n",
    "This section generates additional variations of missing product names  \n",
    "to enhance the dataset for better model training. The steps include:\n",
    "\n",
    "1. **Extracting product details** (SKU & price) from the master file.\n",
    "2. **Generating augmented variations** of missing product names using the `augment_name()` function.\n",
    "3. **Storing the augmented names** along with the corresponding SKU and price.\n",
    "4. **Appending the augmented data** to the original dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to store augmented data\n",
    "augmented_data = []\n",
    "\n",
    "# Iterate over missing names and generate augmented samples\n",
    "for true_name in missing_names:\n",
    "    # Get SKU and price from master file\n",
    "    product_info = master_file.loc[master_file[\"product_name_ar\"] == true_name, [\"sku\", \"price\"]].values\n",
    "    if len(product_info) == 0:\n",
    "        continue  # Skip if no match found (shouldn't happen)\n",
    "\n",
    "    sku, price = product_info[0]  # Extract SKU and price\n",
    "\n",
    "    # Generate augmented names\n",
    "    augmented_names = augment_name(true_name)\n",
    "\n",
    "    for aug_name in augmented_names:\n",
    "        augmented_data.append({\n",
    "            \"seller_item_name\": aug_name,\n",
    "            \"marketplace_product_name_ar\": true_name,\n",
    "            \"sku\": sku,\n",
    "            \"price\": price  # Use actual price from master file\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "augmented_df = pd.DataFrame(augmented_data)\n",
    "\n",
    "# Append to the original dataset\n",
    "dataset = pd.concat([dataset, augmented_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arabic-to-English Number Conversion & English-to-Arabic Translation Dictionary\n",
    "\n",
    "This section prepares necessary data structures for handling product name translations and number conversions:\n",
    "1. **Arabic Number Conversion**: Maps Arabic numerals (٠١٢٣٤٥٦٧٨٩) to English numerals (0123456789).\n",
    "2. **Translation Dictionary**: Creates a dictionary mapping English product names to their Arabic counterparts.\n",
    "3. **Fuzzy Matching List**: Extracts a list of English product names from the master file for similarity matching.\n",
    "4. **English Character Detection Function**: Checks if a given text contains English letters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arabic number conversion dictionary\n",
    "arabic_to_english_numbers = str.maketrans(\"٠١٢٣٤٥٦٧٨٩\", \"0123456789\")\n",
    "\n",
    "# Create a dictionary for English-to-Arabic translation from the Master File\n",
    "translation_dict = dict(zip(master_file[\"product_name\"].astype(str).str.lower(), master_file[\"product_name_ar\"].astype(str)))\n",
    "\n",
    "# List of English product names from the Master File for fuzzy matching\n",
    "master_names_en = list(translation_dict.keys())\n",
    "\n",
    "# Function to check if text contains English characters\n",
    "def contains_english(text):\n",
    "    return bool(re.search(\"[A-Za-z]\", text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `translate_to_arabic(text)`\n",
    "\n",
    "This function translates English product names to Arabic using two approaches:\n",
    "1. **Fuzzy Matching with Master File**:\n",
    "   - Finds the closest English product name match from the Master File.\n",
    "   - If the similarity score is **≥ 50%**, it returns the corresponding Arabic name.\n",
    "2. **Google Translation (Fallback)**:\n",
    "   - If no strong match is found, it translates the text using `GoogleTranslator`.\n",
    "   - Ensures the output is actually in Arabic before returning it.\n",
    "   - This method is considered weak and fails most of the time due to connection problems or API problems,\n",
    "     but it is used because it is free and does not require an API key.\n",
    "3. **Error Handling & Logging**:\n",
    "   - If translation fails, it logs an error and returns the original text.\n",
    "   - If translation returns non-Arabic text, it logs a warning and defaults to the closest match.\n",
    "\n",
    "This helps ensure accurate and reliable translations while minimizing errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to translate English to Arabic (with retry logic)\n",
    "def translate_to_arabic(text):\n",
    "    \"\"\"\n",
    "    Translates English product names to Arabic using:\n",
    "    1. Fuzzy matching with the Master File\n",
    "    2. Google Translator (fallback)\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text (product name).\n",
    "\n",
    "    Returns:\n",
    "        str: Arabic translation of the product name.\n",
    "    \"\"\"\n",
    "    if contains_english(text):   # Only translate if it contains English\n",
    "        # Normalize text before processing\n",
    "        text_lower = text.lower().strip()\n",
    "        text = text.replace('.', ' ')\n",
    "\n",
    "        # Find the closest match from the Master File\n",
    "        match, score, _ = process.extractOne(text_lower, master_names_en, scorer=fuzz.ratio)\n",
    "\n",
    "        # If match is strong (90% similarity or higher), use the Master File translation\n",
    "        if score >= 50:\n",
    "          return translation_dict[match]\n",
    "\n",
    "        try:\n",
    "            # Attempt translation using GoogleTranslator\n",
    "            translated_text = GoogleTranslator(source=\"english\", target=\"arabic\").translate(text_lower)\n",
    "            # Ensure translation is in Arabic\n",
    "            if translated_text and not contains_english(translated_text):\n",
    "                return translated_text\n",
    "            else:\n",
    "                print(f\"Translation did not return Arabic text for: ({text}) and instead return ({translation_dict[match]}) and score : {score}\")\n",
    "                return text  # Return original if translation is not in Arabic\n",
    "        except Exception as e:\n",
    "            print(f\"Translation failed for {text}: {e}\")\n",
    "    return text  # Return original if translation fails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arabic Text Normalization & Cleaning Functions\n",
    "\n",
    "This section defines functions to **clean and normalize Arabic text** for consistency and better processing.  \n",
    "\n",
    "#### **Steps Included:**\n",
    "1. **Remove Diacritics**: Eliminates Arabic **tashkeel** (harakat) such as `َ ُ ِ ّ` to normalize text.\n",
    "2. **Remove Unwanted Words**: Filters out specific words like `\"جديد\"` and `\"سعر\"`, which may add noise.\n",
    "3. **Standardize Arabic Characters**:\n",
    "   - Converts different forms of **Alef** (`أ, إ, آ, ٱ`) to `\"ا\"`.\n",
    "   - Normalizes **Ta Marbuta** (`ة`) to `\"ه\"`, and **Ya** (`ى`) to `\"ي\"`.\n",
    "   - Converts **Hamza-based letters** (`ؤ, ئ`) to `\"و\"` and `\"ي\"`.\n",
    "4. **Remove Non-Arabic Characters**: Excludes **special characters** except numbers and slashes.\n",
    "5. **Convert Arabic Numerals**: Replaces **Arabic digits** (`٠١٢٣٤٥٦٧٨٩`) with **English digits** (`0123456789`).\n",
    "6. **Ensure Proper Spacing**: Standardizes spaces and removes unnecessary symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove diacritics and normalize Arabic text\n",
    "def remove_diacritics(text):\n",
    "    arabic_diacritics = re.compile(\"[\\u064B-\\u0652]\") # Arabic diacritic range\n",
    "    return re.sub(arabic_diacritics, \"\", text)\n",
    "\n",
    "# Function to remove specific unwanted words (\"جديد\" with variations & \"سعر\")\n",
    "def remove_unwanted_words(text):\n",
    "    text = re.sub(r\"جدي+د\", \"\", text)  # Remove \"جديد\" with varying \"ي\" count\n",
    "    text = re.sub(r\"\\bسعر\\b\", \"\", text)  # Remove exact match \"سعر\"\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Remove extra spaces\n",
    "    return text\n",
    "\n",
    "def normalize_arabic(text):\n",
    "    text = str(text).strip()\n",
    "    text = remove_diacritics(text)\n",
    "    text = text.replace(\"أ\", \"ا\").replace(\"إ\", \"ا\").replace(\"آ\", \"ا\")  # Normalize Alef\n",
    "    text = text.replace(\"ى\", \"ي\").replace(\"ة\", \"ه\").replace(\"ٱ\", \"ا\")  # Normalize common variations\n",
    "    text = text.replace(\"ؤ\", \"و\").replace(\"ئ\", \"ي\")  # Normalize more variations\n",
    "    text = re.sub(r\"[^\\u0600-\\u06FF0-9 %\\\\/]\", \"\", text)  # Remove non-Arabic characters except numbers\n",
    "    text = text.translate(arabic_to_english_numbers)  # Convert Arabic numbers to English\n",
    "    text = re.sub(r\"(\\d+)\", r\" \\1 \", text).strip()  # Add spaces before and after numbers\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Remove extra spaces\n",
    "    text = re.sub(r\"ـ+\", \"\", text)  # Remove extensions in words\n",
    "    text = remove_unwanted_words(text)  # Remove \"جديد\" variations and \"سعر\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply normalization to Arabic names in master file and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation did not return Arabic text for: (تلفاست 180 مجم 20قرص  س ج F) and insteat return (فاستل 180 مجم 20 قرص) and score : 38.297872340425535\n",
      "Translation did not return Arabic text for: (كولوفرين A اقرص) and insteat return (كولوفيرين أ 30 قرص) and score : 18.181818181818176\n",
      "Translation did not return Arabic text for: (كولوفرين* 3 شريط01 A) and insteat return (اماريل 3 مجم 30 قرص) and score : 31.57894736842105\n",
      "Translation did not return Arabic text for: (كولوفرينِA3شريط) and insteat return (انتوكس 30 قرص) and score : 14.814814814814813\n",
      "Translation did not return Arabic text for: (كولوفيرين A اقراص) and insteat return (كولوفيرين أ 30 قرص) and score : 17.14285714285714\n",
      "Translation did not return Arabic text for: (تلفاست 120مجم 20 قرص س ج F) and insteat return (فاستل 120 مجم 20 قرص) and score : 34.78260869565217\n",
      "Translation did not return Arabic text for: (تلفاست  120 مجم  اقراصGEG011) and insteat return (شان جيل ملطف 120 جم) and score : 31.818181818181824\n",
      "Translation did not return Arabic text for: (كوبال  اف ج F) and insteat return (اوندالينز 4 مجم 5 فيلم سريع الذوبان بالفم) and score : 29.411764705882348\n",
      "Translation did not return Arabic text for: (اوبلكس شراب سعر جديد  N) and insteat return (ايموكس 500 مجم 16 كبسول) and score : 23.809523809523814\n",
      "Translation did not return Arabic text for: (اماريل إم 3شريط   M) and insteat return (كتافلام 75 مجم / 3 مل 6 امبول) and score : 31.11111111111111\n",
      "Translation did not return Arabic text for: (ترنتال  اقراص/GEG017) and insteat return (ريباريل ان جيل 40 جم) and score : 25.0\n",
      "Translation did not return Arabic text for: (كتافاست فوار س /جديد Y4799) and insteat return (انتريستو 100 مجم 28 قرص) and score : 21.42857142857143\n",
      "Translation did not return Arabic text for: (كتافاست فوار جدييد لا يرتجع Y4826) and insteat return (وانتوثرى شراب 120 مللى) and score : 20.895522388059707\n",
      "Translation did not return Arabic text for: (جوسبيرين 81مجم 60ق/جديد/221370A) and insteat return (اتوريزا 10/20 مجم 21 قرص) and score : 29.629629629629626\n",
      "Translation did not return Arabic text for: (كولوفرين D اقراص 30 قرص) and insteat return (شان لوشن للجسم 300 مل) and score : 31.11111111111111\n",
      "Translation did not return Arabic text for: (كولوفيرين D اقراص) and insteat return (لينكس للبالغين 14 كبسولة) and score : 17.14285714285714\n",
      "Translation did not return Arabic text for: (بليتال 50 مجم 20 قراص X) and insteat return (ديكلاك 150 مجم 20 قرص) and score : 37.2093023255814\n",
      "Translation did not return Arabic text for: (روسيتور 10مجم14 قرص  F) and insteat return (اتور 10 مجم 7 قرص) and score : 31.57894736842105\n",
      "Translation did not return Arabic text for: (كونفنتين 400 سعر جديدEDA) and insteat return (لوفير 400 مجم 10 قرص) and score : 32.55813953488372\n",
      "Translation did not return Arabic text for: (باى بروفينيد 150مجم20 قرص  س ج F) and insteat return (ايموكس 500 مجم 16 كبسول) and score : 31.372549019607842\n",
      "Translation did not return Arabic text for: (ديكساميثازون امبول العامريه/جديد/A615157) and insteat return (اكسفورج اتش سي تي 5/160/12.5 مجم 14 قرص) and score : 19.444444444444443\n",
      "Translation did not return Arabic text for: (امبيزيم 3 شريط EDA) and insteat return (اماريل 3 مجم 30 قرص) and score : 27.77777777777778\n",
      "Translation did not return Arabic text for: (تاريفيد 200مجم 10قرص  س ج F) and insteat return (فلوموسيل 600 مجم 10 قرص فوار) and score : 32.72727272727273\n",
      "Translation did not return Arabic text for: (تاريفيد 200 مجم 10 قرص/DEG012) and insteat return (برافاماكس 200 مجم 10 قرص) and score : 35.29411764705882\n",
      "Translation did not return Arabic text for: (بييلافيكس ق س*ج DA853) and insteat return (روتاسي-60 اقراص) and score : 23.529411764705888\n",
      "Translation did not return Arabic text for: (فيدروب نقط EDA ) and insteat return (كورتيبليكس ب 6 للاطفال 3 امبول) and score : 23.25581395348837\n",
      "Translation did not return Arabic text for: (تافينك 500 مجم اقراص/ج GEG150) and insteat return (سي ريتارد 500 مجم 10 كبسول) and score : 31.372549019607842\n",
      "Translation did not return Arabic text for: (تافنيك 500 اقراص لا يرتجعCEG072) and insteat return (ايموكس 500 مجم 16 كبسول) and score : 31.999999999999996\n",
      "Translation did not return Arabic text for: (تافانيك500مجم 5قرص F) and insteat return (تافانيك 500 محم 5 قرص) and score : 30.000000000000004\n",
      "Translation did not return Arabic text for: (الوكيتا *DSDA/شامبو250مل) and insteat return (الوكيتا دى اس شامبو 250 مل) and score : 30.188679245283023\n",
      "Translation did not return Arabic text for: (الوكيتا شامبو D S) and insteat return (الوكيتا دى اس شامبو 250 مل) and score : 21.739130434782606\n",
      "Translation did not return Arabic text for: (الوكيتا شامبو DS / بيوتي اند بياند) and insteat return (فيجاموكس 0.5 % قطرة عين 5 مل) and score : 25.806451612903224\n",
      "Translation did not return Arabic text for: (فلورست اقراص/جديد/AUAM) and insteat return (اوجرام 1 جم 14 قرص) and score : 20.512820512820518\n",
      "Translation did not return Arabic text for: (ميتاكارديا MR) and insteat return (ار اكس كريم مساج 50 جم) and score : 17.14285714285714\n",
      "Translation did not return Arabic text for: (برونشيكم شراب CEG034***) and insteat return (كو-تارج 80/12.5مجم 14 قرص) and score : 22.72727272727273\n",
      "Translation did not return Arabic text for: (جليمابريد بلس3شريط السعر الجديد G ) and insteat return (تاروليمس 0.03 % مرهم 15 جم) and score : 19.999999999999996\n",
      "Translation did not return Arabic text for: (تيراتام500XR انتبه) and insteat return (كوبال 500 مكجم 30 قرص) and score : 22.22222222222222\n",
      "Translation did not return Arabic text for: (تيراتام 500XR ممتد المفعول اقراص) and insteat return (كوبال 500 مكجم 30 قرص) and score : 28.000000000000004\n",
      "Translation did not return Arabic text for: (ايفكسور 75مجم 14 كبسولة XR) and insteat return (افيكسور اكس آر 75 مجم 14 كبسول) and score : 29.166666666666664\n",
      "Translation did not return Arabic text for: (هاى فريش قطرة/س ج /YLبدون مرتجع) and insteat return (لاسيكس 2مل 3 امبول) and score : 22.22222222222222\n",
      "Translation did not return Arabic text for: (اوتريفين اطفال/نوفارتس س ج/GF2J) and insteat return (نيفيلوب بلس 0.5-25 مجم 20 قرص) and score : 20.68965517241379\n",
      "Translation did not return Arabic text for: (ماكسيلاز شراب/سعر ج/CEG052) and insteat return (بون كير 1 مكجم 30 كبسولة) and score : 20.833333333333336\n",
      "Translation did not return Arabic text for: (ماكسيلاز شراب 100 مل  س ج F) and insteat return (سوبراكس 100مجم / 5 مل شراب معلق 60 مل) and score : 32.14285714285714\n"
     ]
    }
   ],
   "source": [
    "# Apply normalization to Arabic names\n",
    "master_file[\"new_product_name_ar\"] = master_file[\"product_name_ar\"].astype(str).apply(normalize_arabic)\n",
    "dataset[\"new_marketplace_product_name_ar\"] = dataset[\"marketplace_product_name_ar\"].astype(str).apply(normalize_arabic)\n",
    "\n",
    "# Translate only English seller names to Arabic\n",
    "dataset[\"new_seller_item_name\"] = dataset[\"seller_item_name\"].astype(str).apply(translate_to_arabic)\n",
    "\n",
    "# Normalize translated Arabic names\n",
    "dataset[\"new_seller_item_name\"] = dataset[\"new_seller_item_name\"].apply(normalize_arabic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract relevant columns from the dataset and Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant columns\n",
    "seller_names = dataset[\"new_seller_item_name\"].astype(str).values\n",
    "marketplace_names = dataset[\"new_marketplace_product_name_ar\"].astype(str).values\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(seller_names, marketplace_names, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation and Feature Transformation\n",
    "1. **Create TF-IDF Vectorizer**: We are using the `TfidfVectorizer` to convert text data into numerical features.\n",
    "    - `analyzer='char'` specifies that we want to extract character-level features (as opposed to word-level features).\n",
    "    - `ngram_range=(1, 3)` means the vectorizer will consider unigrams (single characters), bigrams (pairs of characters), and trigrams (triplets of characters) for feature extraction.\n",
    "2. **Transform the training dataset into TF-IDF vectors**.\n",
    "3. **Transform the testing dataset into TF-IDF vectors**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(1, 3))\n",
    "\n",
    "# Transform the entire dataset into TF-IDF vectors\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train).astype(np.float32)  # Convert to 32-bit float\n",
    "X_test_tfidf = vectorizer.transform(X_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression model\n",
    "model = LogisticRegression(max_iter=100)\n",
    "start_time = time()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "training_time = time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.9962661443349452\n",
      "Training Time (s): 435.85\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print Performance Metrics\n",
    "print(\"Model Accuracy:\", accuracy)\n",
    "print(\"Training Time (s):\", round(training_time, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Trained Model and Vectorizer\n",
    "The models are saved in the \"models\" directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and vectorizer saved successfully in the 'models' directory!\n"
     ]
    }
   ],
   "source": [
    "# Create the 'models' directory if it doesn't exist\n",
    "if not os.path.exists(\"models\"):\n",
    "    os.makedirs(\"models\")\n",
    "\n",
    "# Define file paths\n",
    "model_path = \"models/logistic_regression_model.pkl\"\n",
    "vectorizer_path = \"models/tfidf_vectorizer.pkl\"\n",
    "\n",
    "# Delete existing files if they exist\n",
    "if os.path.exists(model_path):\n",
    "    os.remove(model_path)\n",
    "if os.path.exists(vectorizer_path):\n",
    "    os.remove(vectorizer_path)\n",
    "\n",
    "# Save the trained model and vectorizer in the 'models' directory\n",
    "joblib.dump(model, model_path)  # Save the trained Logistic Regression model\n",
    "joblib.dump(vectorizer, vectorizer_path)  # Save the TF-IDF vectorizer\n",
    "\n",
    "print(\"Model and vectorizer saved successfully in the 'models' directory!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Trained Model and Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and vectorizer loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the model and vectorizer from the 'models' directory\n",
    "model = joblib.load(\"models/logistic_regression_model.pkl\")\n",
    "vectorizer = joblib.load(\"models/tfidf_vectorizer.pkl\")\n",
    "\n",
    "print(\"Model and vectorizer loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Similarity Function\n",
    "\n",
    "This function computes the similarity between a given seller name and the predicted marketplace name\n",
    "based on the trained model and TF-IDF vectorizer. It also provides a confidence level based on similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(seller_name, model, vectorizer, high_threshhold = 0.8, medium_threshhold = 0.6, Unknown = 0.2,):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        seller_name (str): The name of the seller's product.\n",
    "        model (sklearn.model): The trained machine learning model used for predictions.\n",
    "        vectorizer (sklearn.feature_extraction.text.TfidfVectorizer): The TF-IDF vectorizer used for text feature extraction.\n",
    "        high_threshhold (float, optional): The threshold for classifying the similarity as \"High\". Default is 0.8.\n",
    "        medium_threshhold (float, optional): The threshold for classifying the similarity as \"Medium\". Default is 0.6.\n",
    "        Unknown (float, optional): The threshold below which the result is considered \"Unknown\". Default is 0.2.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing:\n",
    "            - \"seller_name\" (str): The original seller's name.\n",
    "            - \"matched_name\" (str): The predicted marketplace name or \"Not Found\".\n",
    "            - \"similarity_score\" (float): The cosine similarity score between the seller name and matched name.\n",
    "            - \"confidence\" (str): The confidence level based on similarity score (\"High\", \"Medium\", \"Low\", \"Unknown\").\n",
    "            - \"execution_time_ms\" (float): The time taken to compute the similarity in milliseconds.\n",
    "    \"\"\"\n",
    "    # Start time to calculate execution time\n",
    "    start_time = time()\n",
    "\n",
    "    # Transform seller name to TF-IDF vector\n",
    "    seller_vector = vectorizer.transform([seller_name])\n",
    "\n",
    "    # Predict the most likely marketplace name using the TF-IDF vector\n",
    "    predicted_name = model.predict(seller_vector)[0]\n",
    "\n",
    "    # Transform predicted name to TF-IDF vector\n",
    "    predicted_vector = vectorizer.transform([predicted_name])\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarity_score = cosine_similarity(seller_vector, predicted_vector)[0, 0]\n",
    "\n",
    "    # Set confidence levels and handle low similarity cases\n",
    "    if similarity_score < 0.4:\n",
    "        matched_name = \"Not Found\"\n",
    "        confidence = \"Unknown\"\n",
    "        similarity_score = 0.0\n",
    "    else:\n",
    "        matched_name = predicted_name\n",
    "        confidence = \"High\" if similarity_score > high_threshhold else \"Medium\" if similarity_score > medium_threshhold else \"Low\"\n",
    "\n",
    "    execution_time = (time() - start_time) * 1000  # Convert to milliseconds\n",
    "\n",
    "    return {\n",
    "        \"seller_name\": seller_name,\n",
    "        \"matched_name\": matched_name,\n",
    "        \"similarity_score\": round(float(similarity_score), 4),\n",
    "        \"confidence\": confidence,\n",
    "        \"execution_time_ms\": round(execution_time, 2)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Usage of compute_similarity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.9962661443349452\n",
      "Training Time (s): 435.85\n",
      "{'seller_name': '*فلاجيل 500 مجم اقراص 15 ج', 'matched_name': 'فلاجيل 500 مجم 20 قرص', 'similarity_score': 0.7448, 'confidence': 'Medium', 'execution_time_ms': 102.47}\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "example_seller_name = '*فلاجيل 500 مجم اقراص 15 ج' # Replace this with an actual example seller name to test the function.\n",
    "result = compute_similarity(example_seller_name, model, vectorizer)\n",
    "\n",
    "print(\"Model Accuracy:\", accuracy)\n",
    "print(\"Training Time (s):\", round(training_time, 2))\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
