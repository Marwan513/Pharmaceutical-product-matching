{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries\n",
    "\n",
    "This cell imports various Python libraries needed for data processing, machine learning, and text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from time import time\n",
    "from rapidfuzz import process, fuzz\n",
    "from deep_translator import GoogleTranslator\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Preparing the Dataset\n",
    "\n",
    "This section loads The Excel file containing product matching data.  \n",
    "It reads two sheets:  \n",
    "1. **Master File** - Likely contains reference product names.  \n",
    "2. **Dataset** - Contains new product names that need to be matched.  \n",
    "Duplicates in the dataset are removed to ensure data consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Excel dataset\n",
    "file_path = \"Product Matching Dataset.xlsx\" # edit the path if you want to train on another data\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# Read both sheets\n",
    "master_file = pd.read_excel(xls, sheet_name=\"Master File\")\n",
    "dataset = pd.read_excel(xls, sheet_name=\"Dataset\")\n",
    "\n",
    "# Remove duplicate entries from the dataset\n",
    "dataset = dataset.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Missing Product Names\n",
    "\n",
    "This section extracts product names from both the dataset and master file  \n",
    "to identify missing product names that are present in the master file but not in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get missing product names\n",
    "existing_names = set(dataset[\"marketplace_product_name_ar\"].unique())\n",
    "all_names = set(master_file[\"product_name_ar\"].unique())\n",
    "missing_names = list(all_names - existing_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `augment_name(name)`\n",
    "\n",
    "This function generates **augmented variations** of a given product name  \n",
    "to simulate different possible representations of the same name.  \n",
    "It applies multiple random transformations such as:\n",
    "- **Shuffling words** within the name\n",
    "- **Removing digits** (e.g., `0`)\n",
    "- **Deleting random characters** from words\n",
    "- **Replacing random characters** with Arabic letters\n",
    "- **Appending random suffixes** (e.g., `\"جديد\"`, `\"سعر جديد\"`)\n",
    "\n",
    "This is useful for training models that need to handle variations in  \n",
    "product naming conventions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_name(name):\n",
    "    \"\"\"\n",
    "    Generates augmented variations of the input name by applying random transformations.\n",
    "    \n",
    "    Args:\n",
    "        name (str): The original product name.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of unique augmented product names.\n",
    "    \"\"\"\n",
    "    augmented_names = set() # Store unique augmented names\n",
    "\n",
    "    for _ in range(70): # Generate multiple variations\n",
    "        modified_name = name\n",
    "\n",
    "         # Randomly shuffle words in the name (50% probability)\n",
    "        if random.random() < 0.5:\n",
    "            words = modified_name.split()\n",
    "            if len(words) > 1:\n",
    "                random.shuffle(words)\n",
    "                modified_name = \" \".join(words)\n",
    "\n",
    "        # Randomly remove the digit '0' from the name (50% probability)\n",
    "        if random.random() < 0.5:\n",
    "            modified_name = re.sub(\"0\", \"\", modified_name, 1)\n",
    "\n",
    "        words = modified_name.split()\n",
    "\n",
    "        for i, word in enumerate(words):\n",
    "            # Randomly delete a character from words longer than 5 letters (50% probability)\n",
    "            if len(word) > 5 and random.random() < 0.5:\n",
    "                idx = random.randint(0, len(word) - 1)\n",
    "                words[i] = word[:idx] + word[idx+1:]\n",
    "\n",
    "            # Randomly replace a character with an Arabic letter (50% probability)\n",
    "            if len(word) > 5 and random.random() < 0.5:\n",
    "                idx = random.randint(0, len(word) - 1)\n",
    "                new_char = random.choice(\"ابتثجحخدذرزسشصضطظعغفقكلمنهوي\")\n",
    "                words[i] = word[:idx] + new_char + word[idx+1:]\n",
    "\n",
    "        modified_name = \" \".join(words)\n",
    "        \n",
    "        # Randomly append a suffix (50% probability)\n",
    "        if random.random() < 0.5:\n",
    "            suffix = random.choice([\"جديد\", \"سعر\", \"سعر جديد\", \"س ج\"])\n",
    "            modified_name = f\"{modified_name} {suffix}\".strip()\n",
    "            \n",
    "        # Add the modified name to the set (ensuring uniqueness)\n",
    "        augmented_names.add(modified_name)\n",
    "\n",
    "    return list(augmented_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmenting Missing Product Names and Expanding the Dataset\n",
    "\n",
    "This section generates additional variations of missing product names  \n",
    "to enhance the dataset for better model training. The steps include:\n",
    "\n",
    "1. **Extracting product details** (SKU & price) from the master file.\n",
    "2. **Generating augmented variations** of missing product names using the `augment_name()` function.\n",
    "3. **Storing the augmented names** along with the corresponding SKU and price.\n",
    "4. **Appending the augmented data** to the original dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to store augmented data\n",
    "augmented_data = []\n",
    "\n",
    "# Iterate over missing names and generate augmented samples\n",
    "for true_name in missing_names:\n",
    "    # Get SKU and price from master file\n",
    "    product_info = master_file.loc[master_file[\"product_name_ar\"] == true_name, [\"sku\", \"price\"]].values\n",
    "    if len(product_info) == 0:\n",
    "        continue  # Skip if no match found (shouldn't happen)\n",
    "\n",
    "    sku, price = product_info[0]  # Extract SKU and price\n",
    "\n",
    "    # Generate augmented names\n",
    "    augmented_names = augment_name(true_name)\n",
    "\n",
    "    for aug_name in augmented_names:\n",
    "        augmented_data.append({\n",
    "            \"seller_item_name\": aug_name,\n",
    "            \"marketplace_product_name_ar\": true_name,\n",
    "            \"sku\": sku,\n",
    "            \"price\": price  # Use actual price from master file\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "augmented_df = pd.DataFrame(augmented_data)\n",
    "\n",
    "# Append to the original dataset\n",
    "dataset = pd.concat([dataset, augmented_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arabic-to-English Number Conversion & English-to-Arabic Translation Dictionary\n",
    "\n",
    "This section prepares necessary data structures for handling product name translations and number conversions:\n",
    "1. **Arabic Number Conversion**: Maps Arabic numerals (٠١٢٣٤٥٦٧٨٩) to English numerals (0123456789).\n",
    "2. **Translation Dictionary**: Creates a dictionary mapping English product names to their Arabic counterparts.\n",
    "3. **Fuzzy Matching List**: Extracts a list of English product names from the master file for similarity matching.\n",
    "4. **English Character Detection Function**: Checks if a given text contains English letters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arabic number conversion dictionary\n",
    "arabic_to_english_numbers = str.maketrans(\"٠١٢٣٤٥٦٧٨٩\", \"0123456789\")\n",
    "\n",
    "# Create a dictionary for English-to-Arabic translation from the Master File\n",
    "translation_dict = dict(zip(master_file[\"product_name\"].astype(str).str.lower(), master_file[\"product_name_ar\"].astype(str)))\n",
    "\n",
    "# List of English product names from the Master File for fuzzy matching\n",
    "master_names_en = list(translation_dict.keys())\n",
    "\n",
    "# Function to check if text contains English characters\n",
    "def contains_english(text):\n",
    "    return bool(re.search(\"[A-Za-z]\", text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `translate_to_arabic(text)`\n",
    "\n",
    "This function translates English product names to Arabic using two approaches:\n",
    "1. **Fuzzy Matching with Master File**:\n",
    "   - Finds the closest English product name match from the Master File.\n",
    "   - If the similarity score is **≥ 50%**, it returns the corresponding Arabic name.\n",
    "2. **Google Translation (Fallback)**:\n",
    "   - If no strong match is found, it translates the text using `GoogleTranslator`.\n",
    "   - Ensures the output is actually in Arabic before returning it.\n",
    "   - This method is considered weak and fails most of the time due to connection problems or API problems,\n",
    "     but it is used because it is free and does not require an API key.\n",
    "3. **Error Handling & Logging**:\n",
    "   - If translation fails, it logs an error and returns the original text.\n",
    "   - If translation returns non-Arabic text, it logs a warning and defaults to the closest match.\n",
    "\n",
    "This helps ensure accurate and reliable translations while minimizing errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to translate English to Arabic (with retry logic)\n",
    "def translate_to_arabic(text):\n",
    "    \"\"\"\n",
    "    Translates English product names to Arabic using:\n",
    "    1. Fuzzy matching with the Master File\n",
    "    2. Google Translator (fallback)\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text (product name).\n",
    "\n",
    "    Returns:\n",
    "        str: Arabic translation of the product name.\n",
    "    \"\"\"\n",
    "    if contains_english(text):   # Only translate if it contains English\n",
    "        # Normalize text before processing\n",
    "        text_lower = text.lower().strip()\n",
    "        text = text.replace('.', ' ')\n",
    "\n",
    "        # Find the closest match from the Master File\n",
    "        match, score, _ = process.extractOne(text_lower, master_names_en, scorer=fuzz.ratio)\n",
    "\n",
    "        # If match is strong (90% similarity or higher), use the Master File translation\n",
    "        if score >= 50:\n",
    "          return translation_dict[match]\n",
    "\n",
    "        try:\n",
    "            # Attempt translation using GoogleTranslator\n",
    "            translated_text = GoogleTranslator(source=\"english\", target=\"arabic\").translate(text_lower)\n",
    "            # Ensure translation is in Arabic\n",
    "            if translated_text and not contains_english(translated_text):\n",
    "                return translated_text\n",
    "            else:\n",
    "                print(f\"Translation did not return Arabic text for: ({text}) and insteat return ({translation_dict[match]}) and score : {score}\")\n",
    "                return text  # Return original if translation is not in Arabic\n",
    "        except Exception as e:\n",
    "            print(f\"Translation failed for {text}: {e}\")\n",
    "    return text  # Return original if translation fails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arabic Text Normalization & Cleaning Functions\n",
    "\n",
    "This section defines functions to **clean and normalize Arabic text** for consistency and better processing.  \n",
    "\n",
    "#### **Steps Included:**\n",
    "1. **Remove Diacritics**: Eliminates Arabic **tashkeel** (harakat) such as `َ ُ ِ ّ` to normalize text.\n",
    "2. **Remove Unwanted Words**: Filters out specific words like `\"جديد\"` and `\"سعر\"`, which may add noise.\n",
    "3. **Standardize Arabic Characters**:\n",
    "   - Converts different forms of **Alef** (`أ, إ, آ, ٱ`) to `\"ا\"`.\n",
    "   - Normalizes **Ta Marbuta** (`ة`) to `\"ه\"`, and **Ya** (`ى`) to `\"ي\"`.\n",
    "   - Converts **Hamza-based letters** (`ؤ, ئ`) to `\"و\"` and `\"ي\"`.\n",
    "4. **Remove Non-Arabic Characters**: Excludes **special characters** except numbers and slashes.\n",
    "5. **Convert Arabic Numerals**: Replaces **Arabic digits** (`٠١٢٣٤٥٦٧٨٩`) with **English digits** (`0123456789`).\n",
    "6. **Ensure Proper Spacing**: Standardizes spaces and removes unnecessary symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove diacritics and normalize Arabic text\n",
    "def remove_diacritics(text):\n",
    "    arabic_diacritics = re.compile(\"[\\u064B-\\u0652]\") # Arabic diacritic range\n",
    "    return re.sub(arabic_diacritics, \"\", text)\n",
    "\n",
    "# Function to remove specific unwanted words (\"جديد\" with variations & \"سعر\")\n",
    "def remove_unwanted_words(text):\n",
    "    text = re.sub(r\"جدي+د\", \"\", text)  # Remove \"جديد\" with varying \"ي\" count\n",
    "    text = re.sub(r\"\\bسعر\\b\", \"\", text)  # Remove exact match \"سعر\"\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Remove extra spaces\n",
    "    return text\n",
    "\n",
    "def normalize_arabic(text):\n",
    "    text = str(text).strip()\n",
    "    text = remove_diacritics(text)\n",
    "    text = text.replace(\"أ\", \"ا\").replace(\"إ\", \"ا\").replace(\"آ\", \"ا\")  # Normalize Alef\n",
    "    text = text.replace(\"ى\", \"ي\").replace(\"ة\", \"ه\").replace(\"ٱ\", \"ا\")  # Normalize common variations\n",
    "    text = text.replace(\"ؤ\", \"و\").replace(\"ئ\", \"ي\")  # Normalize more variations\n",
    "    text = re.sub(r\"[^\\u0600-\\u06FF0-9 %\\\\/]\", \"\", text)  # Remove non-Arabic characters except numbers\n",
    "    text = text.translate(arabic_to_english_numbers)  # Convert Arabic numbers to English\n",
    "    text = re.sub(r\"(\\d+)\", r\" \\1 \", text).strip()  # Add spaces before and after numbers\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Remove extra spaces\n",
    "    text = re.sub(r\"ـ+\", \"\", text)  # Remove extensions in words\n",
    "    text = remove_unwanted_words(text)  # Remove \"جديد\" variations and \"سعر\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply normalization to Arabic names in master file and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation failed for تلفاست 180 مجم 20قرص  س ج F: تلفاست 180 مجم 20قرص  س.ج f --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for دايجينورم شرابEDA: دايجينورم شرابeda --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for كولوفرين A اقرص: كولوفرين a اقرص --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for كولوفرين* 3 شريط01 A: كولوفرين* 3 شريط01 a --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for كولوفرينِA3شريط: كولوفرينِa3شريط --> No translation was found using the current translator. Try another translator?\n",
      "Translation did not return Arabic text for: (كولوفيرين A اقراص) and insteat return (كولوفيرين أ 30 قرص) and score : 17.14285714285714\n",
      "Translation failed for تلفاست 120مجم 20 قرص س ج F: تلفاست 120مجم 20 قرص س.ج f --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for تلفاست  120 مجم  اقراصGEG011: تلفاست  120 مجم  اقراصgeg011 --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for كوبال  اف ج F: كوبال  اف ج f --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for نانازوكسيد شراب س جEDA: نانازوكسيد شراب س جeda --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for اوبلكس شراب N: اوبلكس شراب n --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for اوبلكس شراب سعر جديد  N: اوبلكس شراب سعر جديد  n --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for اماريل ام MMM  : اماريل ام mmm --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for اماريل M 2مجم : اماريل m 2مجم --> No translation was found using the current translator. Try another translator?\n",
      "Translation did not return Arabic text for: (اماريل إم 3شريط   M) and insteat return (كتافلام 75 مجم / 3 مل 6 امبول) and score : 31.11111111111111\n",
      "Translation did not return Arabic text for: (ترنتال  اقراص/GEG017) and insteat return (ريباريل ان جيل 40 جم) and score : 25.0\n",
      "Translation failed for كتافاست فوار س /جديد Y4799: كتافاست فوار س /جديد y4799 --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for كتافاست فوار جدييد لا يرتجع Y4826: كتافاست فوار جدييد لا يرتجع y4826 --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for جوسبيرين 81مجم 60ق/جديد/221370A: جوسبيرين 81مجم 60ق/جديد/221370a --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for كولوفرين D اقراص 30 قرص: كولوفرين d اقراص 30 قرص --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for كولوفيرين D اقراص: كولوفيرين d اقراص --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for بليتال 50 مجم 20 قراص X: بليتال 50 مجم 20 قراص x --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for روسيتور 10مجم14 قرص  F: روسيتور 10مجم14 قرص  f --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for كونفنتين 400 سعر جديدEDA: كونفنتين 400 سعر جديدeda --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for باى بروفينيد 150مجم20 قرص  س ج F: باى بروفينيد 150مجم20 قرص  س.ج f --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for سينجولير10مجم 14 قرصEDA: سينجولير10مجم 14 قرصeda --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for ديكساميثازون امبول العامريه/جديد/A615157: ديكساميثازون امبول العامريه/جديد/a615157 --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for امبيزيم 3 شريط EDA: امبيزيم 3 شريط eda --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for تاريفيد 200مجم 10قرص  س ج F: تاريفيد 200مجم 10قرص  س.ج f --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for تاريفيد 200 مجم 10 قرص/DEG012: تاريفيد 200 مجم 10 قرص/deg012 --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for بييلافيكس ق س*ج DA853: بييلافيكس ق س*ج da853 --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for فيدروب نقط EDA : فيدروب نقط eda --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for تافينك 500 مجم اقراص/ج GEG150: تافينك 500 مجم اقراص/ج geg150 --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for تافنيك 500 اقراص لا يرتجعCEG072: تافنيك 500 اقراص لا يرتجعceg072 --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for تافانيك500مجم 5قرص F: تافانيك500مجم 5قرص f --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for روسيتور20مجم14قرص  F: روسيتور20مجم14قرص  f --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for الوكيتا *DSDA/شامبو250مل: الوكيتا *dsda/شامبو250مل --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for الوكيتا شامبو D S: الوكيتا شامبو d s --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for الوكيتا شامبو DS / بيوتي اند بياند: الوكيتا شامبو ds / بيوتي اند بياند --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for فلورست اقراص/جديد/AUAM: فلورست اقراص/جديد/auam --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for ميتاكارديا MR: ميتاكارديا mr --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for برونشيكم شراب CEG034***: برونشيكم شراب ceg034*** --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for برونشيكم شراب 100 مل  F: برونشيكم شراب 100 مل  f --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for لوبريفيسك نقطM : لوبريفيسك نقطm --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for داونوبرازول 40 ك  س*جA  : داونوبرازول 40 ك  س*جa --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for برونتوجيست امبول EDA ®: برونتوجيست امبول eda ® --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for جليمابريد بلس3شريط السعر الجديد G : جليمابريد بلس3شريط السعر الجديد g --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for تيراتام500XR انتبه: تيراتام500xr انتبه --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for تيراتام 500XR ممتد المفعول اقراص: تيراتام 500xr ممتد المفعول اقراص --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for ايفكسور 75مجم 14 كبسولة XR: ايفكسور 75مجم 14 كبسولة xr --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for هاى فريش قطرة YK0231***: هاى فريش قطرة yk0231*** --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for هاى فريش قطرة/س ج /YLبدون مرتجع: هاى فريش قطرة/س ج /ylبدون مرتجع --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for اوتريفين اطفال/نوفارتس س ج/GF2J: اوتريفين اطفال/نوفارتس س ج/gf2j --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for ماكسيلاز شراب/سعر ج/CEG052: ماكسيلاز شراب/سعر ج/ceg052 --> No translation was found using the current translator. Try another translator?\n",
      "Translation failed for ماكسيلاز شراب 100 مل  س ج F: ماكسيلاز شراب 100 مل  س.ج f --> No translation was found using the current translator. Try another translator?\n"
     ]
    }
   ],
   "source": [
    "# Apply normalization to Arabic names\n",
    "master_file[\"new_product_name_ar\"] = master_file[\"product_name_ar\"].astype(str).apply(normalize_arabic)\n",
    "dataset[\"new_marketplace_product_name_ar\"] = dataset[\"marketplace_product_name_ar\"].astype(str).apply(normalize_arabic)\n",
    "\n",
    "# Translate only English seller names to Arabic\n",
    "dataset[\"new_seller_item_name\"] = dataset[\"seller_item_name\"].astype(str).apply(translate_to_arabic)\n",
    "\n",
    "# Normalize translated Arabic names\n",
    "dataset[\"new_seller_item_name\"] = dataset[\"new_seller_item_name\"].apply(normalize_arabic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract relevant columns from the dataset and Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant columns\n",
    "seller_names = dataset[\"new_seller_item_name\"].astype(str).values\n",
    "marketplace_names = dataset[\"new_marketplace_product_name_ar\"].astype(str).values\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(seller_names, marketplace_names, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation and Feature Transformation\n",
    "1. **Create TF-IDF Vectorizer**: We are using the `TfidfVectorizer` to convert text data into numerical features.\n",
    "    - `analyzer='char'` specifies that we want to extract character-level features (as opposed to word-level features).\n",
    "    - `ngram_range=(1, 3)` means the vectorizer will consider unigrams (single characters), bigrams (pairs of characters), and trigrams (triplets of characters) for feature extraction.\n",
    "2. **Transform the training dataset into TF-IDF vectors**.\n",
    "3. **Transform the testing dataset into TF-IDF vectors**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(1, 3))\n",
    "\n",
    "# Transform the entire dataset into TF-IDF vectors\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train).astype(np.float32)  # Convert to 32-bit float\n",
    "X_test_tfidf = vectorizer.transform(X_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression model\n",
    "model = LogisticRegression(max_iter=100)\n",
    "start_time = time()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "training_time = time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.9963298262784438\n",
      "Training Time (s): 244.6\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print Performance Metrics\n",
    "print(\"Model Accuracy:\", accuracy)\n",
    "print(\"Training Time (s):\", round(training_time, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Trained Model and Vectorizer\n",
    "The models are saved in the \"models\" directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and vectorizer saved successfully in the 'models' directory!\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model and vectorizer in the 'models' directory\n",
    "joblib.dump(model, \"models/logistic_regression_model.pkl\") # Save the trained Logistic Regression model\n",
    "joblib.dump(vectorizer, \"models/tfidf_vectorizer.pkl\") # Save the TF-IDF vectorizer\n",
    "\n",
    "print(\"Model and vectorizer saved successfully in the 'models' directory!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Trained Model and Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and vectorizer loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the model and vectorizer from the 'models' directory\n",
    "model = joblib.load(\"models/logistic_regression_model.pkl\")\n",
    "vectorizer = joblib.load(\"models/tfidf_vectorizer.pkl\")\n",
    "\n",
    "print(\"Model and vectorizer loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Similarity Function\n",
    "\n",
    "This function computes the similarity between a given seller name and the predicted marketplace name\n",
    "based on the trained model and TF-IDF vectorizer. It also provides a confidence level based on similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(seller_name, model, vectorizer, high_threshhold = 0.8, medium_threshhold = 0.6, Unknown = 0.2,):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        seller_name (str): The name of the seller's product.\n",
    "        model (sklearn.model): The trained machine learning model used for predictions.\n",
    "        vectorizer (sklearn.feature_extraction.text.TfidfVectorizer): The TF-IDF vectorizer used for text feature extraction.\n",
    "        high_threshhold (float, optional): The threshold for classifying the similarity as \"High\". Default is 0.8.\n",
    "        medium_threshhold (float, optional): The threshold for classifying the similarity as \"Medium\". Default is 0.6.\n",
    "        Unknown (float, optional): The threshold below which the result is considered \"Unknown\". Default is 0.2.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing:\n",
    "            - \"seller_name\" (str): The original seller's name.\n",
    "            - \"matched_name\" (str): The predicted marketplace name or \"Not Found\".\n",
    "            - \"similarity_score\" (float): The cosine similarity score between the seller name and matched name.\n",
    "            - \"confidence\" (str): The confidence level based on similarity score (\"High\", \"Medium\", \"Low\", \"Unknown\").\n",
    "            - \"execution_time_ms\" (float): The time taken to compute the similarity in milliseconds.\n",
    "    \"\"\"\n",
    "    # Start time to calculate execution time\n",
    "    start_time = time()\n",
    "\n",
    "    # Transform seller name to TF-IDF vector\n",
    "    seller_vector = vectorizer.transform([seller_name])\n",
    "\n",
    "    # Predict the most likely marketplace name using the TF-IDF vector\n",
    "    predicted_name = model.predict(seller_vector)[0]\n",
    "\n",
    "    # Transform predicted name to TF-IDF vector\n",
    "    predicted_vector = vectorizer.transform([predicted_name])\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarity_score = cosine_similarity(seller_vector, predicted_vector)[0, 0]\n",
    "\n",
    "    # Set confidence levels and handle low similarity cases\n",
    "    if similarity_score < 0.4:\n",
    "        matched_name = \"Not Found\"\n",
    "        confidence = \"Unknown\"\n",
    "        similarity_score = 0.0\n",
    "    else:\n",
    "        matched_name = predicted_name\n",
    "        confidence = \"High\" if similarity_score > high_threshhold else \"Medium\" if similarity_score > medium_threshhold else \"Low\"\n",
    "\n",
    "    execution_time = (time() - start_time) * 1000  # Convert to milliseconds\n",
    "\n",
    "    return {\n",
    "        \"seller_name\": seller_name,\n",
    "        \"matched_name\": matched_name,\n",
    "        \"similarity_score\": round(float(similarity_score), 4),\n",
    "        \"confidence\": confidence,\n",
    "        \"execution_time_ms\": round(execution_time, 2)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Usage of compute_similarity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.9963298262784438\n",
      "Training Time (s): 244.6\n",
      "{'seller_name': '*فلاجيل 500 مجم اقراص 15 ج', 'matched_name': 'فلاجيل 500 مجم 20 قرص', 'similarity_score': 0.7441, 'confidence': 'Medium', 'execution_time_ms': 123.96}\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "example_seller_name = '*فلاجيل 500 مجم اقراص 15 ج' # Replace this with an actual example seller name to test the function.\n",
    "result = compute_similarity(example_seller_name, model, vectorizer)\n",
    "\n",
    "print(\"Model Accuracy:\", accuracy)\n",
    "print(\"Training Time (s):\", round(training_time, 2))\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
